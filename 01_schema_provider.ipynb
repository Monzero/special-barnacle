{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d3fe5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.108.0)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.16.2)\n",
      "Requirement already satisfied: openpyxl in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (3.1.5)\n",
      "Requirement already satisfied: rank_bm25 in ./venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (2.11.9)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: et-xmlfile in ./venv/lib/python3.12/site-packages (from openpyxl->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6403fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up\n",
    "import os\n",
    "import sys\n",
    "import subprocess   \n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "source_schema_path = './01_input/01_source_CTR.xlsx'\n",
    "target_schema_path = './01_input/02_Target.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a5f29792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRIMMED COLUMN NAME', 'Entry #', 'Subject Area',\n",
       "       'Current CTR Definition Field Name', 'Data Type', 'Business Definition',\n",
       "       'Usage', 'Required Field? (Y/N)', 'Notes/Values', 'CHR?', 'Table Name',\n",
       "       'Column Name', 'Optum Extract Data Name', 'Optum Notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading source and target schema files\n",
    "df_source_schema = pd.read_excel(source_schema_path, header=0)\n",
    "df_source_schema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8029da0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TRIMMED COLUMN NAME",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Entry #",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Subject Area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current CTR Definition Field Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Data Type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Business Definition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Usage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Required Field? (Y/N)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Notes/Values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "CHR?",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Table Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Column Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Optum Extract Data Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Optum Notes",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b5deba2c-aee8-410b-8541-058ef18cb07f",
       "rows": [
        [
         "0",
         "ACCESS_FEE",
         "1",
         "Financial",
         "CTR-ACCESS-FEE",
         "9(7)V99",
         "Fee to pay for access to a provider network",
         "B",
         "Y",
         null,
         "N",
         "IADS003_FINAN",
         "ACCESS_FEE",
         "PFIN-ACCESS-FEE",
         null
        ],
        [
         "1",
         "NNH-FEE-INDICATOR",
         "2",
         "Process",
         "CTR-ACCESS-FEE-INDICATOR",
         null,
         "Determines if the vendor was primary or secondary network",
         "B",
         "Y",
         null,
         null,
         "IADS013_NNH",
         "NNH-FEE-INDICATOR",
         "PNNH-NNH-FEE-INDICATOR",
         null
        ],
        [
         "2",
         "ACCID-DT",
         "3",
         "Medical",
         "CTR-ACCIDENT-DATE",
         "9(8), DATE",
         "Date of accident / injury",
         "B",
         "Y",
         null,
         "Y",
         "IADS009_MED_INST, IADS009_MED_PROF",
         "ACCID-DT",
         "PINS-ACC-DT, PPROF-ACC-DT",
         null
        ],
        [
         "3",
         "ACCID-DT-TYPE",
         "4",
         "Medical",
         "CTR-ACCIDENT-DATE-TYPE",
         "X",
         "Code for significant event occurring at ctr-accident-date",
         "B",
         "Y",
         null,
         "Y",
         "IADS009_MED_INST, IADS009_MED_PROF",
         "ACCID-DT-TYPE",
         "PINS-ACC-TYPE, PPROF-ACC-TYPE",
         null
        ],
        [
         "4",
         "ACCT-ID",
         "5",
         "Not to be used",
         "CTR-ACCOUNT-ID",
         "X(4)",
         "(Not to be used) – Defines the financial checking account",
         "B",
         "N",
         "Concatenates the Bank ID and the Bank Seq columns. Bank ID and Band Seq will be stored separately",
         "Y",
         "IADS102",
         "ACCT-ID",
         "PCRM-ACCT-ID",
         "Defines the financial checking account"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIMMED COLUMN NAME</th>\n",
       "      <th>Entry #</th>\n",
       "      <th>Subject Area</th>\n",
       "      <th>Current CTR Definition Field Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Business Definition</th>\n",
       "      <th>Usage</th>\n",
       "      <th>Required Field? (Y/N)</th>\n",
       "      <th>Notes/Values</th>\n",
       "      <th>CHR?</th>\n",
       "      <th>Table Name</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Optum Extract Data Name</th>\n",
       "      <th>Optum Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCESS_FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>Financial</td>\n",
       "      <td>CTR-ACCESS-FEE</td>\n",
       "      <td>9(7)V99</td>\n",
       "      <td>Fee to pay for access to a provider network</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>IADS003_FINAN</td>\n",
       "      <td>ACCESS_FEE</td>\n",
       "      <td>PFIN-ACCESS-FEE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NNH-FEE-INDICATOR</td>\n",
       "      <td>2</td>\n",
       "      <td>Process</td>\n",
       "      <td>CTR-ACCESS-FEE-INDICATOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Determines if the vendor was primary or second...</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IADS013_NNH</td>\n",
       "      <td>NNH-FEE-INDICATOR</td>\n",
       "      <td>PNNH-NNH-FEE-INDICATOR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCID-DT</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>CTR-ACCIDENT-DATE</td>\n",
       "      <td>9(8), DATE</td>\n",
       "      <td>Date of accident / injury</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>IADS009_MED_INST, IADS009_MED_PROF</td>\n",
       "      <td>ACCID-DT</td>\n",
       "      <td>PINS-ACC-DT, PPROF-ACC-DT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCID-DT-TYPE</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>CTR-ACCIDENT-DATE-TYPE</td>\n",
       "      <td>X</td>\n",
       "      <td>Code for significant event occurring at ctr-ac...</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>IADS009_MED_INST, IADS009_MED_PROF</td>\n",
       "      <td>ACCID-DT-TYPE</td>\n",
       "      <td>PINS-ACC-TYPE, PPROF-ACC-TYPE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCT-ID</td>\n",
       "      <td>5</td>\n",
       "      <td>Not to be used</td>\n",
       "      <td>CTR-ACCOUNT-ID</td>\n",
       "      <td>X(4)</td>\n",
       "      <td>(Not to be used) – Defines the financial check...</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>Concatenates the Bank ID and the Bank Seq colu...</td>\n",
       "      <td>Y</td>\n",
       "      <td>IADS102</td>\n",
       "      <td>ACCT-ID</td>\n",
       "      <td>PCRM-ACCT-ID</td>\n",
       "      <td>Defines the financial checking account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIMMED COLUMN NAME  Entry #    Subject Area  \\\n",
       "0          ACCESS_FEE        1       Financial   \n",
       "1   NNH-FEE-INDICATOR        2         Process   \n",
       "2            ACCID-DT        3         Medical   \n",
       "3       ACCID-DT-TYPE        4         Medical   \n",
       "4             ACCT-ID        5  Not to be used   \n",
       "\n",
       "  Current CTR Definition Field Name   Data Type  \\\n",
       "0                    CTR-ACCESS-FEE     9(7)V99   \n",
       "1          CTR-ACCESS-FEE-INDICATOR         NaN   \n",
       "2                 CTR-ACCIDENT-DATE  9(8), DATE   \n",
       "3            CTR-ACCIDENT-DATE-TYPE           X   \n",
       "4                    CTR-ACCOUNT-ID        X(4)   \n",
       "\n",
       "                                 Business Definition Usage  \\\n",
       "0        Fee to pay for access to a provider network     B   \n",
       "1  Determines if the vendor was primary or second...     B   \n",
       "2                          Date of accident / injury     B   \n",
       "3  Code for significant event occurring at ctr-ac...     B   \n",
       "4  (Not to be used) – Defines the financial check...     B   \n",
       "\n",
       "  Required Field? (Y/N)                                       Notes/Values  \\\n",
       "0                     Y                                                NaN   \n",
       "1                     Y                                                NaN   \n",
       "2                     Y                                                NaN   \n",
       "3                     Y                                                NaN   \n",
       "4                     N  Concatenates the Bank ID and the Bank Seq colu...   \n",
       "\n",
       "  CHR?                          Table Name        Column Name  \\\n",
       "0    N                       IADS003_FINAN         ACCESS_FEE   \n",
       "1  NaN                         IADS013_NNH  NNH-FEE-INDICATOR   \n",
       "2    Y  IADS009_MED_INST, IADS009_MED_PROF           ACCID-DT   \n",
       "3    Y  IADS009_MED_INST, IADS009_MED_PROF      ACCID-DT-TYPE   \n",
       "4    Y                             IADS102            ACCT-ID   \n",
       "\n",
       "         Optum Extract Data Name                             Optum Notes  \n",
       "0                PFIN-ACCESS-FEE                                     NaN  \n",
       "1         PNNH-NNH-FEE-INDICATOR                                     NaN  \n",
       "2      PINS-ACC-DT, PPROF-ACC-DT                                     NaN  \n",
       "3  PINS-ACC-TYPE, PPROF-ACC-TYPE                                     NaN  \n",
       "4                   PCRM-ACCT-ID  Defines the financial checking account  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source_schema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a6e7c4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OI PDI CDM Name', 'Valid Values', 'Nullable', 'Format',\n",
       "       'Implementation Notes', 'Level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_schema = pd.read_excel(target_schema_path, header=0)\n",
    "df_target_schema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cc584b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subsetting the target schema just to make sample testing faster\n",
    "\n",
    "df_target_schema = df_target_schema.iloc[50:53]  # only from row 51 to 60 (0-based index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "88c022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Create schema chunks\n",
    "def make_source_schema_chunks(df, table_name):\n",
    "    chunks = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Safely get each field, defaulting to empty string if not present\n",
    "        trimmed_col = str(row.get('TRIMMED COLUMN NAME', ''))\n",
    "        subject_area = str(row.get('Subject Area', ''))\n",
    "        data_type = str(row.get('Data Type', ''))\n",
    "        business_def = str(row.get('Business Definition', ''))\n",
    "        tbl_name = str(row.get('Table Name', table_name))\n",
    "        col_name = str(row.get('Column Name', trimmed_col))\n",
    "        opt_cols = str(row.get('Optum Extract Data Name', ''))\n",
    "        \n",
    "        # Compose chunk text\n",
    "        chunk = f\"Column name is {col_name} from the table {tbl_name} and subject area {subject_area} | Its data type is {data_type} and more information about it - {business_def}\"\n",
    "        if 'not to be used' in chunk.lower() or 'do not use' in chunk.lower() or 'deprecated' in chunk.lower():\n",
    "            continue\n",
    "        \n",
    "        chunks.append({\n",
    "            'trimmed_column_name': trimmed_col,\n",
    "            'table_name': tbl_name,\n",
    "            'column_name': col_name,\n",
    "            'subject_area': subject_area,\n",
    "            'data_type': data_type,\n",
    "            'business_definition': business_def,\n",
    "            'chunk': chunk\n",
    "        })\n",
    "    #print(chunks)\n",
    "    return chunks\n",
    "\n",
    "def make_target_schema_chunks(df):\n",
    "    chunks = []\n",
    "    for _, row in df.iterrows():\n",
    "        field_name = str(row.get('OI PDI CDM Name', ''))\n",
    "        valid_values = str(row.get('Valid Values', ''))\n",
    "        is_nullable = str(row.get('Nullable', ''))\n",
    "        field_format = str(row.get('Format', ''))\n",
    "        imp_notes = str(row.get('Implementation Notes', ''))\n",
    "        # Compose chunk text\n",
    "        chunk = f\"We need to make {field_name} and its valid values are {valid_values}, is_nullable:  {is_nullable} and its format is {field_format}, special instructions: {imp_notes}\"\n",
    "        chunks.append({\n",
    "            'field_name': field_name,\n",
    "            'valid_values': valid_values,\n",
    "            'is_nullable': is_nullable,\n",
    "            'field_format': field_format,\n",
    "            'imp_notes': imp_notes,\n",
    "            'chunk': chunk\n",
    "        })\n",
    "    #print(chunks)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5fe84737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source and target schema chunks\n",
    "source_chunks = make_source_schema_chunks(df_source_schema, \"source_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9de2ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chunks = make_target_schema_chunks(df_target_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "94c69f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Get embeddings for a list of chunks\n",
    "def get_embeddings(chunks):\n",
    "    texts = [c['chunk'] for c in chunks]\n",
    "    response = openai.embeddings.create(input=texts, model=\"text-embedding-ada-002\")\n",
    "    for i, emb in enumerate(response.data):\n",
    "        chunks[i]['embedding'] = emb.embedding\n",
    "    return chunks\n",
    "\n",
    "source_chunks = get_embeddings(source_chunks)\n",
    "target_chunks = get_embeddings(target_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4d6c0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Helper: Tokenize for BM25\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Prepare BM25 corpus for source chunks\n",
    "bm25_corpus = [tokenize(chunk['chunk']) for chunk in source_chunks]\n",
    "bm25 = BM25Okapi(bm25_corpus)\n",
    "\n",
    "# Helper: Find top N relevant source fields for a target chunk using both semantic and BM25\n",
    "def find_top_n_sources_combined(target_chunk, source_chunks, n=10, bm25_weight=0.5, emb_weight=0.5):\n",
    "    # Semantic similarity (cosine)\n",
    "    target_emb = target_chunk['embedding']\n",
    "    semantic_scores = []\n",
    "    for s in source_chunks:\n",
    "        sim = 1 - cosine(target_emb, s['embedding'])\n",
    "        semantic_scores.append(sim)\n",
    "    # BM25 similarity\n",
    "    query_tokens = tokenize(target_chunk['chunk'])\n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    # Combine scores\n",
    "    combined_scores = []\n",
    "    for i in range(len(source_chunks)):\n",
    "        score = bm25_weight * bm25_scores[i] + emb_weight * semantic_scores[i]\n",
    "        combined_scores.append((source_chunks[i], score))\n",
    "    combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [s[0] for s in combined_scores[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c44c0fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Chunk: We need to make Claim Total Billed Amount and its valid values are nan, is_nullable:  Yes and its format is nan, special instructions: nan\n",
      "Top 20 Relevant Source Chunks (BM25 + Semantic):\n",
      "1. Column name is ADJST-AMT from the table IADS006_PROCS and subject area Financial | Its data type is S9(7)V99 and more information about it - Total adjustment amount applied for a claim\n",
      "2. Column name is CHECK-AMT from the table IADS006_PROCS and subject area Process | Its data type is S9(7)V99 and more information about it - Total amount of the check this claim was included on\n",
      "3. Column name is LT-MED-ADJ-AMT from the table IADS003_FINAN and subject area Financial | Its data type is S9(9)V99 and more information about it - Total amount of lifetime medical benefits paid to date\n",
      "4. Column name is GROSS-PAY from the table IADS004_REV and subject area Revenue | Its data type is S9(7)V99 and more information about it - Negotiated amount the provider has agreed to accept as payment in full for covered services. Valid field for hospitals claims only.\n",
      "5. Column name is OI_PAID_AMT from the table IADS001_BILL_LINE and subject area Bill Line | Its data type is S9(7)V99 and more information about it - Total amount paid by other insurance\n",
      "\n",
      "Prompt sent to LLM:\n",
      " Given the following relevant source fields (as JSON):\n",
      "[{'summary': 'Column name is ADJST-AMT from the table IADS006_PROCS and subject area Financial | Its data type is S9(7)V99 and more information about it - Total adjustment amount applied for a claim'}, {'summary': 'Column name is CHECK-AMT from the table IADS006_PROCS and subject area Process | Its data type is S9(7)V99 and more information about it - Total amount of the check this claim was included on'}, {'summary': 'Column name is LT-MED-ADJ-AMT from the table IADS003_FINAN and subject area Financial | Its data type is S9(9)V99 and more information about it - Total amount of lifetime medical benefits paid to date'}, {'summary': 'Column name is GROSS-PAY from the table IADS004_REV and subject area Revenue | Its data type is S9(7)V99 and more information about it - Negotiated amount the provider has agreed to accept as payment in full for covered services. Valid field for hospitals claims only.'}, {'summary': 'Column name is OI_PAID_AMT from the table IADS001_BILL_LINE and subject area Bill Line | Its data type is S9(7)V99 and more information about it - Total amount paid by other insurance'}]\n",
      "\n",
      "And the following target field (as JSON):\n",
      "{'summary': 'We need to make Claim Total Billed Amount and its valid values are nan, is_nullable:  Yes and its format is nan, special instructions: nan'}\n",
      "\n",
      "nan or na shows that the field is not specified, hence you can ignore that field in your reasoning. \n",
      "Special focus on interpreting the field name and valid values to understand the target field requirements.\n",
      "Provide a transformation rule in this JSON format:\n",
      "{\n",
      "  \"target_table\": \"<target_table_name>\",\n",
      "  \"target_field\": \"<target_field_name>\",\n",
      "  \"source_table\": \"<source_table_name or list>\",\n",
      "  \"source_field\": \"<source_field_name or list>\",\n",
      "  \"transformation\": \"<describe transformation or mapping logic>\"\n",
      "}\n",
      "Be explicit about any type conversions, calculations, or renaming.\n",
      "\n",
      "Target Chunk: We need to make Claim Total Patient Liability Amount and its valid values are nan, is_nullable:  Yes and its format is nan, special instructions: nan\n",
      "Top 20 Relevant Source Chunks (BM25 + Semantic):\n",
      "1. Column name is PAT_LIAB from the table IADS001_BILL_LINE and subject area Bill Line | Its data type is S9(7)V99 and more information about it - Total patient responsibility for this line\n",
      "2. Column name is PAT-DAYS from the table IADS007_MED_INST and subject area Medical | Its data type is S9(3) and more information about it - Total number of days - patient stay\n",
      "3. Column name is ADJST-AMT from the table IADS006_PROCS and subject area Financial | Its data type is S9(7)V99 and more information about it - Total adjustment amount applied for a claim\n",
      "4. Column name is CHECK-AMT from the table IADS006_PROCS and subject area Process | Its data type is S9(7)V99 and more information about it - Total amount of the check this claim was included on\n",
      "5. Column name is LT-MED-ADJ-AMT from the table IADS003_FINAN and subject area Financial | Its data type is S9(9)V99 and more information about it - Total amount of lifetime medical benefits paid to date\n",
      "\n",
      "Prompt sent to LLM:\n",
      " Given the following relevant source fields (as JSON):\n",
      "[{'summary': 'Column name is PAT_LIAB from the table IADS001_BILL_LINE and subject area Bill Line | Its data type is S9(7)V99 and more information about it - Total patient responsibility for this line'}, {'summary': 'Column name is PAT-DAYS from the table IADS007_MED_INST and subject area Medical | Its data type is S9(3) and more information about it - Total number of days - patient stay'}, {'summary': 'Column name is ADJST-AMT from the table IADS006_PROCS and subject area Financial | Its data type is S9(7)V99 and more information about it - Total adjustment amount applied for a claim'}, {'summary': 'Column name is CHECK-AMT from the table IADS006_PROCS and subject area Process | Its data type is S9(7)V99 and more information about it - Total amount of the check this claim was included on'}, {'summary': 'Column name is LT-MED-ADJ-AMT from the table IADS003_FINAN and subject area Financial | Its data type is S9(9)V99 and more information about it - Total amount of lifetime medical benefits paid to date'}]\n",
      "\n",
      "And the following target field (as JSON):\n",
      "{'summary': 'We need to make Claim Total Patient Liability Amount and its valid values are nan, is_nullable:  Yes and its format is nan, special instructions: nan'}\n",
      "\n",
      "nan or na shows that the field is not specified, hence you can ignore that field in your reasoning. \n",
      "Special focus on interpreting the field name and valid values to understand the target field requirements.\n",
      "Provide a transformation rule in this JSON format:\n",
      "{\n",
      "  \"target_table\": \"<target_table_name>\",\n",
      "  \"target_field\": \"<target_field_name>\",\n",
      "  \"source_table\": \"<source_table_name or list>\",\n",
      "  \"source_field\": \"<source_field_name or list>\",\n",
      "  \"transformation\": \"<describe transformation or mapping logic>\"\n",
      "}\n",
      "Be explicit about any type conversions, calculations, or renaming.\n",
      "\n",
      "Target Chunk: We need to make Claim Total Patient CoPay Amount and its valid values are nan, is_nullable:  Yes and its format is nan, special instructions: nan\n",
      "Top 20 Relevant Source Chunks (BM25 + Semantic):\n",
      "1. Column name is PAT_LIAB from the table IADS001_BILL_LINE and subject area Bill Line | Its data type is S9(7)V99 and more information about it - Total patient responsibility for this line\n",
      "2. Column name is PAT-DAYS from the table IADS007_MED_INST and subject area Medical | Its data type is S9(3) and more information about it - Total number of days - patient stay\n",
      "3. Column name is ADJST-AMT from the table IADS006_PROCS and subject area Financial | Its data type is S9(7)V99 and more information about it - Total adjustment amount applied for a claim\n",
      "4. Column name is CHECK-AMT from the table IADS006_PROCS and subject area Process | Its data type is S9(7)V99 and more information about it - Total amount of the check this claim was included on\n",
      "5. Column name is LT-MED-ADJ-AMT from the table IADS003_FINAN and subject area Financial | Its data type is S9(9)V99 and more information about it - Total amount of lifetime medical benefits paid to date\n",
      "\n",
      "Prompt sent to LLM:\n",
      " Given the following relevant source fields (as JSON):\n",
      "[{'summary': 'Column name is PAT_LIAB from the table IADS001_BILL_LINE and subject area Bill Line | Its data type is S9(7)V99 and more information about it - Total patient responsibility for this line'}, {'summary': 'Column name is PAT-DAYS from the table IADS007_MED_INST and subject area Medical | Its data type is S9(3) and more information about it - Total number of days - patient stay'}, {'summary': 'Column name is ADJST-AMT from the table IADS006_PROCS and subject area Financial | Its data type is S9(7)V99 and more information about it - Total adjustment amount applied for a claim'}, {'summary': 'Column name is CHECK-AMT from the table IADS006_PROCS and subject area Process | Its data type is S9(7)V99 and more information about it - Total amount of the check this claim was included on'}, {'summary': 'Column name is LT-MED-ADJ-AMT from the table IADS003_FINAN and subject area Financial | Its data type is S9(9)V99 and more information about it - Total amount of lifetime medical benefits paid to date'}]\n",
      "\n",
      "And the following target field (as JSON):\n",
      "{'summary': 'We need to make Claim Total Patient CoPay Amount and its valid values are nan, is_nullable:  Yes and its format is nan, special instructions: nan'}\n",
      "\n",
      "nan or na shows that the field is not specified, hence you can ignore that field in your reasoning. \n",
      "Special focus on interpreting the field name and valid values to understand the target field requirements.\n",
      "Provide a transformation rule in this JSON format:\n",
      "{\n",
      "  \"target_table\": \"<target_table_name>\",\n",
      "  \"target_field\": \"<target_field_name>\",\n",
      "  \"source_table\": \"<source_table_name or list>\",\n",
      "  \"source_field\": \"<source_field_name or list>\",\n",
      "  \"transformation\": \"<describe transformation or mapping logic>\"\n",
      "}\n",
      "Be explicit about any type conversions, calculations, or renaming.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage in your main loop:\n",
    "all_rules = []\n",
    "for target_chunk in target_chunks:\n",
    "    relevant_sources = find_top_n_sources_combined(target_chunk, source_chunks, n=5)\n",
    "    print(f\"\\nTarget Chunk: {target_chunk['chunk']}\")\n",
    "    print(\"Top 20 Relevant Source Chunks (BM25 + Semantic):\")\n",
    "    for idx, s in enumerate(relevant_sources, 1):\n",
    "        print(f\"{idx}. {s['chunk']}\")\n",
    "    # Prepare JSON for LLM\n",
    "    relevant_source_json = [\n",
    "        {\n",
    "            #'trimmed_column_name': s.get('trimmed_column_name', ''),\n",
    "            #'table_name': s.get('table_name', ''),\n",
    "            #'column_name': s.get('column_name', ''),\n",
    "            #'subject_area': s.get('subject_area', ''),\n",
    "            #'data_type': s.get('data_type', ''),\n",
    "            #'business_definition': s.get('business_definition', ''),\n",
    "            'summary': s.get('chunk', '')\n",
    "        }\n",
    "        for s in relevant_sources\n",
    "    ]\n",
    "    target_json = {\n",
    "        #'field_name': target_chunk.get('field_name', ''),\n",
    "        #'valid_values': target_chunk.get('valid_values', ''),\n",
    "        #'is_nullable': target_chunk.get('is_nullable', ''),\n",
    "        #'field_format': target_chunk.get('field_format', ''),\n",
    "        #'imp_notes': target_chunk.get('imp_notes', ''),\n",
    "        'summary': target_chunk.get('chunk', '')\n",
    "    }\n",
    "    prompt = (\n",
    "        f\"Given the following relevant source fields (as JSON):\\n{relevant_source_json}\\n\\n\"\n",
    "        f\"And the following target field (as JSON):\\n{target_json}\\n\\n\"\n",
    "        \"nan or na shows that the field is not specified, hence you can ignore that field in your reasoning. \\n\"\n",
    "        \"Special focus on interpreting the field name and valid values to understand the target field requirements.\\n\"\n",
    "        \"Provide a transformation rule in this JSON format:\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"target_table\\\": \\\"<target_table_name>\\\",\\n\"\n",
    "        \"  \\\"target_field\\\": \\\"<target_field_name>\\\",\\n\"\n",
    "        \"  \\\"source_table\\\": \\\"<source_table_name or list>\\\",\\n\"\n",
    "        \"  \\\"source_field\\\": \\\"<source_field_name or list>\\\",\\n\"\n",
    "        \"  \\\"transformation\\\": \\\"<describe transformation or mapping logic>\\\"\\n\"\n",
    "        \"}\\n\"\n",
    "        \"Be explicit about any type conversions, calculations, or renaming.\"\n",
    "    )\n",
    "    print(\"\\nPrompt sent to LLM:\\n\", prompt)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data engineer who writes data transformation rules.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    all_rules.append(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fdbb6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['```json\\n{\\n  \"target_table\": \"Claims\",\\n  \"target_field\": \"Claim Total Billed Amount\",\\n  \"source_table\": [\"IADS006_PROCS\", \"IADS003_FINAN\", \"IADS004_REV\", \"IADS001_BILL_LINE\"],\\n  \"source_field\": [\"ADJST-AMT\", \"CHECK-AMT\", \"LT-MED-ADJ-AMT\", \"GROSS-PAY\", \"OI_PAID_AMT\"],\\n  \"transformation\": \"Calculate the sum of ADJST-AMT, CHECK-AMT, LT-MED-ADJ-AMT, GROSS-PAY, and OI_PAID_AMT to derive the total billed amount for the claim.\"\\n}\\n```',\n",
       " '{\\n  \"target_table\": \"Claims\",\\n  \"target_field\": \"Claim_Total_Patient_Liability_Amount\",\\n  \"source_table\": [\"IADS001_BILL_LINE\", \"IADS006_PROCS\"],\\n  \"source_field\": [\"PAT_LIAB\", \"ADJST-AMT\"],\\n  \"transformation\": \"Calculate the sum of PAT_LIAB from table IADS001_BILL_LINE and ADJST-AMT from table IADS006_PROCS to derive the total patient liability amount for a claim.\"\\n}',\n",
       " '```json\\n{\\n  \"target_table\": \"Claim\",\\n  \"target_field\": \"TotalPatientCoPayAmount\",\\n  \"source_table\": [\"IADS001_BILL_LINE\", \"IADS006_PROCS\"],\\n  \"source_field\": [\"PAT_LIAB\", \"ADJST-AMT\"],\\n  \"transformation\": \"Calculate the sum of PAT_LIAB from table IADS001_BILL_LINE and ADJST-AMT from table IADS006_PROCS to derive the total patient copay amount for a claim.\"\\n}\\n```']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ae92547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save all rules to 03_output\n",
    "os.makedirs('./03_output', exist_ok=True)\n",
    "with open('./03_output/transformation_rules.json', 'w') as f:\n",
    "    for rule in all_rules:\n",
    "        f.write(rule + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
